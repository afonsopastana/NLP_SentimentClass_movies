{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Sentiment classification for a movie data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook aims to perform a \"sentiment classification\" on a movie review data set. The main goal is to comprehend how different techniques of data preprocessing and text encoding change the performance in the prediction.\n",
    "\n",
    "### Summary:\n",
    "* Loading data\n",
    "* Bag of Words\n",
    "* TF-IDF\n",
    "* Word2vec - VBOW\n",
    "* Word2vec - Skip Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data set is divided into ```train``` and ```test``` data sets. Both of them are balanced, which is the ideal for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "[\"The undoubted highlight of this movie is Peter O'Toole's performance. In turn wildly comical and terribly terribly tragic. Does anybody do it better than O'Toole? I don't think so. What a great face that man has!<br /><br />The story is an odd one and quite disturbing and emotionally intense in parts (especially toward the end) but it is also oddly touching and does succeed on many levels. However, I felt the film basically revolved around Peter O'Toole's luminous performance and I'm sure I wouldn't have enjoyed it even half as much if he hadn't been in it.\", 1]\n",
      "\n",
      "Number of test reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "['Although credit should have been given to Dr. Seuess for stealing the story-line of \"Horton Hatches The Egg\", this was a fine film. It touched both the emotions and the intellect. Due especially to the incredible performance of seven year old Justin Henry and a script that was sympathetic to each character (and each one\\'s predicament), the thought provoking elements linger long after the tear jerking ones are over. Overall, superior acting from a solid cast, excellent directing, and a very powerful script. The right touches of humor throughout help keep a \"heavy\" subject from becoming tedious or difficult to sit through. Lastly, this film stands the test of time and seems in no way dated, decades after it was released.', 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Loading json\n",
    "with open(\"ressources/json_pol\",encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "    json_data = json.loads(data[0])\n",
    "    train = json_data[\"train\"]\n",
    "    test = json_data[\"test\"]\n",
    "\n",
    "# Quick Check\n",
    "counter_train = Counter((x[1] for x in train))\n",
    "counter_test = Counter((x[1] for x in test))\n",
    "print(\"Number of train reviews : \", len(train))\n",
    "print(\"----> # of positive : \", counter_train[1])\n",
    "print(\"----> # of negative : \", counter_train[0])\n",
    "print(\"\")\n",
    "print(train[0])\n",
    "print(\"\")\n",
    "print(\"Number of test reviews : \",len(test))\n",
    "print(\"----> # of positive : \", counter_test[1])\n",
    "print(\"----> # of negative : \", counter_test[0])\n",
    "\n",
    "print(\"\")\n",
    "print(test[0])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From TRAIN data set\n",
    "classes = [pol for text,pol in train] # y_train\n",
    "corpus = [text for text,pol in train] # X_train\n",
    "\n",
    "# From TEST data set\n",
    "true = [pol for text,pol in test] #y_test\n",
    "test_corpus = [text for text,pol in test] #X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start with the ```Bag of words``` encoding. Here the goal is to change parameters into the ```CountVectorizer()``` function and see how it affects the model performance.\n",
    "\n",
    "* ```default```: the encoding with all the parameters set to their default;\n",
    "* ```stopwors```: removing stopwords from the dictionary, that means removing very frequent words that have no effect on classifying as good or bad review;\n",
    "* ```rm frequent```: removes frequent words, in our case, words that appear at least 90% of the time in the documents;\n",
    "* ```rm rare```: removes rare words, in our case, words that appear less than 10% of the time in the documents;\n",
    "* ```bigram```: makes tokens composed of two words;\n",
    "* ```un and bigram```: makes tokens composed of one or two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "dic_bagOfWords = {\n",
    "    \"default\": [CountVectorizer()],\n",
    "    \"stopwords\": [CountVectorizer(stop_words='english')],\n",
    "    \"rm frequent\": [CountVectorizer(max_df=0.9)],\n",
    "    \"rm rare\": [CountVectorizer(min_df=0.1)], \n",
    "    \"bigram\": [CountVectorizer(ngram_range=(2,2))],\n",
    "    \"uni and bigram\": [CountVectorizer(ngram_range=(1,2))]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a function to evaluate all these possibilities of encoding, fitting three models (```Naive bayes```, ```Logistic regression``` and ```SVM```). The values of accuracy from the three models will be used to evaluate if the change in ```CounterVectorizer()``` brings improvemement or not to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def eval_preprocessing(train_corpus=corpus, test_corpus=test_corpus, train_classes=classes, test_classes=true, dic_levels=dic_bagOfWords):\n",
    "    for title, vecto in list(dic_levels.items()):\n",
    "        vectorizer = vecto[0]\n",
    "        X = vectorizer.fit_transform(train_corpus)\n",
    "        \n",
    "        #Naïve Bayes\n",
    "        nb_clf = MultinomialNB()\n",
    "        nb_clf.fit(X, train_classes)\n",
    "\n",
    "        #Logistic Regression\n",
    "        lr_clf = LogisticRegression(random_state=0, solver='lbfgs',n_jobs=-1)\n",
    "        lr_clf.fit(X, train_classes)\n",
    "\n",
    "        #Linear SVM\n",
    "        svm_clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "        svm_clf.fit(X, train_classes)\n",
    "\n",
    "        X_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "        pred_nb = nb_clf.predict(X_test)\n",
    "        pred_lr = lr_clf.predict(X_test)\n",
    "        pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "        acc_nb = accuracy_score(test_classes, pred_nb)\n",
    "        acc_lr = accuracy_score(test_classes, pred_lr)\n",
    "        acc_svm = accuracy_score(test_classes, pred_svm)\n",
    "\n",
    "        print(f\"Naïve Bayes accuracy for {title}: {acc_nb}\")\n",
    "        print(f\"Logistic Regression accuracy for {title}: {acc_lr}\")\n",
    "        print(f\"SVM accuracy for {title}: {acc_svm}\")\n",
    "\n",
    "        dic_levels[title].extend([acc_nb, acc_lr, acc_svm])\n",
    "\n",
    "    return dic_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we evaluate the first suggestions we had to improve the prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "eval_bagOfWords = eval_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bow = pd.DataFrame(eval_bagOfWords)\n",
    "eval_bow.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_bow = eval_bow.set_index('index')\n",
    "eval_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bow.to_csv('results_txt/bow1.txt', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_scores = ['acc_nb', 'acc_lr', 'acc_svm']\n",
    "colors = [\"#4C0099\", \"#FFB3B3\", \"#8fce00\"]\n",
    "\n",
    "data = pd.DataFrame(eval_bagOfWords)\n",
    "data.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "data = data.set_index('index')\n",
    "data = data.T\n",
    "data = data.reset_index()\n",
    "data = data[['naiveBayes', 'logisticRegression', 'SVM']]\n",
    "labels = [CountVectorizer(),\n",
    " CountVectorizer(stop_words='english'),\n",
    " CountVectorizer(max_df=0.9),\n",
    " CountVectorizer(min_df=0.1),\n",
    " CountVectorizer(ngram_range=(2, 2)),\n",
    " CountVectorizer(ngram_range=(1, 2))]\n",
    "fig, ax= plt.subplots(figsize = (12,6))\n",
    "\n",
    "ax.set_ylim(0.5, 1.02)\n",
    "ax = sns.lineplot(data = data[['naiveBayes', 'logisticRegression', 'SVM']], palette=colors , dashes=False)\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=90, multialignment=\"left\", fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the most efficient parameter was the tokenizer with one or two words by token. The stopwords didn't bring any improvement to our prediction, but eliminating the frequent words worked better.\n",
    "\n",
    "Further, we are going to explore other preprocessing techniques that could improve our model as well. We keep some that showed good result in the previous analyses and we add others:\n",
    "\n",
    "* ```trigram```: token made of three words;\n",
    "* ```uni to trigram```: token made of one to three words;\n",
    "* ```bi to trigram```: token made of two to three words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bagOfWords_v2 = {\n",
    "    \"default\": [CountVectorizer()],\n",
    "    \"rm frequent\": [CountVectorizer(max_df=0.9)],\n",
    "    \"bigram\": [CountVectorizer(ngram_range=(2,2))],\n",
    "    \"uni and bigram\": [CountVectorizer(ngram_range=(1,2))],\n",
    "    'trigram': [CountVectorizer(ngram_range=(3,3))],\n",
    "    'uni to trigram': [CountVectorizer(ngram_range=(1,3))],\n",
    "    'bi to trigram': [CountVectorizer(ngram_range=(2,3))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bagOfWords_v2 = eval_preprocessing(dic_levels=dic_bagOfWords_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bow_v2 = pd.DataFrame(eval_bagOfWords_v2)\n",
    "eval_bow_v2.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_bow_v2 = eval_bow_v2.set_index('index')\n",
    "eval_bow_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(eval_bagOfWords_v2)\n",
    "data.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "data = data.set_index('index')\n",
    "data = data.T\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_scores = ['acc_nb', 'acc_lr', 'acc_svm']\n",
    "colors = [\"#4C0099\", \"#FFB3B3\", \"#8fce00\"]\n",
    "\n",
    "data = pd.DataFrame(eval_bagOfWords_v2)\n",
    "data.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "data = data.set_index('index')\n",
    "data = data.T\n",
    "data = data.reset_index()\n",
    "data = data[['naiveBayes', 'logisticRegression', 'SVM']]\n",
    "labels = [CountVectorizer(),\n",
    " CountVectorizer(max_df=0.9),\n",
    " CountVectorizer(ngram_range=(2, 2)),\n",
    " CountVectorizer(ngram_range=(1, 2)),\n",
    " CountVectorizer(ngram_range=(3, 3)),\n",
    " CountVectorizer(ngram_range=(1, 3)),\n",
    " CountVectorizer(ngram_range=(2, 3))]\n",
    "fig, ax= plt.subplots(figsize = (12,6))\n",
    "\n",
    "ax.set_ylim(0.5, 1.02)\n",
    "ax = sns.lineplot(data = data[['naiveBayes', 'logisticRegression', 'SVM']], palette=colors , dashes=False)\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=90, multialignment=\"left\", fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next analyses are turned to lemmatization and removing special characters or small words (until three lettres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "    \n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Transforms text to remove unwanted bits.\n",
    "    \"\"\"\n",
    "    text.replace('[^\\w\\s]', '') # for ponctuation\n",
    "    text.replace(r'(\\b\\w{1,3}\\b)', '') # for words with 3 letters or less\n",
    "    text.replace('\\d+', '') # for digits\n",
    "\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_lem = {'lemma': [CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode',\n",
    "                                lowercase = True)],\n",
    "     'rm elements': [CountVectorizer(preprocessor=preprocess)]\n",
    "                                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lemma = eval_preprocessing(dic_levels=dic_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lemma = pd.DataFrame(eval_lemma)\n",
    "eval_lemma.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_lemma = eval_lemma.set_index('index')\n",
    "eval_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last step we will assemble the best techniques into the same encoding to see how the models perform with their combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bagOfWords_v3 = {\n",
    "    \"default\": [CountVectorizer()],\n",
    "    'assembled': [CountVectorizer(max_df=0.9,\n",
    "                                  ngram_range=(1,3),\n",
    "                                  tokenizer=LemmaTokenizer(),\n",
    "                                  preprocessor=preprocess)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_assemb = eval_preprocessing(dic_levels=dic_bagOfWords_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_assemb_df = pd.DataFrame(eval_assemb)\n",
    "eval_assemb_df.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_assemb_df = eval_assemb_df.set_index('index')\n",
    "eval_assemb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we try the TF-IDF encoder and repeat the same steps we did before in the ```bag of words```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dic_tfidf = {\n",
    "    'default': [TfidfVectorizer()],\n",
    "    \"stopwords\": [CountVectorizer(stop_words='english')],\n",
    "    \"rm frequent\": [TfidfVectorizer(max_df=0.9)],\n",
    "    'rm rare': [TfidfVectorizer(min_df=0.1)],\n",
    "    \"bigram\": [TfidfVectorizer(ngram_range=(2,2))],\n",
    "    \"uni and bigram\": [TfidfVectorizer(ngram_range=(1,2))],\n",
    "    'trigram': [TfidfVectorizer(ngram_range=(3,3))],\n",
    "    'uni to trigram': [TfidfVectorizer(ngram_range=(1,3))],\n",
    "    'bi to trigram': [TfidfVectorizer(ngram_range=(2,3))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tfidf = eval_preprocessing(dic_levels=dic_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tfidf_df = pd.DataFrame(eval_tfidf)\n",
    "eval_tfidf_df.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_tfidf_df = eval_tfidf_df.set_index('index')\n",
    "eval_tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_scores = ['acc_nb', 'acc_lr', 'acc_svm']\n",
    "colors = [\"#4C0099\", \"#FFB3B3\", \"#8fce00\"]\n",
    "\n",
    "data = pd.DataFrame(eval_tfidf)\n",
    "data.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "data = data.set_index('index')\n",
    "data = data.T\n",
    "data = data.reset_index()\n",
    "data = data[['naiveBayes', 'logisticRegression', 'SVM']]\n",
    "labels = [TfidfVectorizer(),\n",
    " CountVectorizer(stop_words='english'),\n",
    " TfidfVectorizer(max_df=0.9),\n",
    " TfidfVectorizer(min_df=0.1),\n",
    " TfidfVectorizer(ngram_range=(2, 2)),\n",
    " TfidfVectorizer(ngram_range=(1, 2)),\n",
    " TfidfVectorizer(ngram_range=(3, 3)),\n",
    " TfidfVectorizer(ngram_range=(1, 3)),\n",
    " TfidfVectorizer(ngram_range=(2, 3))]\n",
    "fig, ax= plt.subplots(figsize = (12,6))\n",
    "\n",
    "ax.set_ylim(0.5, 1.02)\n",
    "ax = sns.lineplot(data = data[['naiveBayes', 'logisticRegression', 'SVM']], palette=colors , dashes=False)\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=90, multialignment=\"left\", fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tfidf_v2 = {'default': [TfidfVectorizer()],\n",
    "                'lemma': [TfidfVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                strip_accents = 'unicode',\n",
    "                                lowercase = True)],\n",
    "                'rm elements': [TfidfVectorizer(preprocessor=preprocess)]\n",
    "                                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tfidf_v2 = eval_preprocessing(dic_levels=dic_tfidf_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tfidf_df2 = pd.DataFrame(eval_tfidf_v2)\n",
    "eval_tfidf_df2.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_tfidf_df2 = eval_tfidf_df2.set_index('index')\n",
    "eval_tfidf_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_assemb_tfidf = {\n",
    "    \"default\": [TfidfVectorizer()],\n",
    "    'assembled': [TfidfVectorizer(max_df=0.9,\n",
    "                                  ngram_range=(1,3),\n",
    "                                  tokenizer=LemmaTokenizer(),\n",
    "                                  preprocessor=preprocess)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_assemb_tfidf = eval_preprocessing(dic_levels=dic_assemb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tfidf_df3 = pd.DataFrame(eval_assemb_tfidf)\n",
    "eval_tfidf_df3.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_tfidf_df3 = eval_tfidf_df3.set_index('index')\n",
    "eval_tfidf_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec - CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are trying a method of word embedding to see how our model performs. In the word2vec model, all words become a vector and the similarity between words are calculated by the cosinus between both vectors.\n",
    "\n",
    "In this first step we use the word2vec with the ```continuous bag of word``` structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "text = [t.split() for t,p in train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the word2vec model, which is going to fit a vector for every word in our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=0, hs=0, negative=5,        \n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the aggregation of vectors in order to train our model, we will try different solutions:\n",
    "* ``mean()``\n",
    "* ```sum()```\n",
    "* ```min()```\n",
    "* ```max()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "\n",
    "def vectorize_mean(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.mean(vec, axis = 0)\n",
    "\n",
    "    return vec2\n",
    "    \n",
    "\n",
    "def vectorize_sum(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.sum(vec, axis = 0)\n",
    "\n",
    "    return vec2\n",
    "\n",
    "\n",
    "def vectorize_min(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.min(vec, axis = 0)\n",
    "\n",
    "    return vec2\n",
    "\n",
    "\n",
    "def vectorize_max(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.max(vec, axis = 0)\n",
    "\n",
    "    return vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "results = {}\n",
    "################### mean ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_mean(text) for text,pol in train]\n",
    "X_test = [vectorize_mean(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results.update({'mean': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for mean aggregation: \", acc_lr)\n",
    "\n",
    "################### sum ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_sum(text) for text,pol in train]\n",
    "X_test = [vectorize_sum(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results.update({'sum': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for sum aggregation: \", acc_lr)\n",
    "\n",
    "################### minimum ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_min(text) for text,pol in train]\n",
    "X_test = [vectorize_min(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results.update({'min': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for minimum aggregation: \", acc_lr)\n",
    "\n",
    "################### maximum ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_max(text) for text,pol in train]\n",
    "X_test = [vectorize_max(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results.update({'max': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for maximum aggregation: \", acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the aggregation method, taking the mean of vectors seems to be the best choise when trying to do predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wors2vec - Skip Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try the word2vec with the ```Skip gram``` structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "text = [t.split() for t,p in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=1, hs=0, negative=5,        \n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "\n",
    "def vectorize_mean(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.mean(vec, axis = 0)\n",
    "\n",
    "    return vec2\n",
    "    \n",
    "\n",
    "def vectorize_sum(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.sum(vec, axis = 0)\n",
    "\n",
    "    return vec2\n",
    "\n",
    "\n",
    "def vectorize_min(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.min(vec, axis = 0)\n",
    "\n",
    "    return vec2\n",
    "\n",
    "\n",
    "def vectorize_max(text,mean=False):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word in w2v.wv.key_to_index:\n",
    "            vecteur = w2v.wv[word]\n",
    "            vec.append(vecteur)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    vec2 = np.max(vec, axis = 0)\n",
    "\n",
    "    return vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results_sg = {}\n",
    "################### mean ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_mean(text) for text,pol in train]\n",
    "X_test = [vectorize_mean(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results_sg.update({'mean': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for mean aggregation: \", acc_lr)\n",
    "\n",
    "################### sum ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_sum(text) for text,pol in train]\n",
    "X_test = [vectorize_sum(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results_sg.update({'sum': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for sum aggregation: \", acc_lr)\n",
    "\n",
    "################### minimum ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_min(text) for text,pol in train]\n",
    "X_test = [vectorize_min(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results_sg.update({'min': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for minimum aggregation: \", acc_lr)\n",
    "\n",
    "################### maximum ################################\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize_max(text) for text,pol in train]\n",
    "X_test = [vectorize_max(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, classes)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(true, y_pred)\n",
    "\n",
    "results_sg.update({'max': [acc_lr]})\n",
    "\n",
    "print(\"accuracy for maximum aggregation: \", acc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tests we performed here, the one that seems to work the best is the ```bag of words encoding```, with some modifications to the intern parameters of the function.\n",
    "\n",
    "The ```word2vec``` performed better when used with the ```skip gram``` architecture and the mean aggregation.\n",
    "\n",
    "For better performances of prediction we would consider applying hyperparameters tuning for the models we chose to train or even changing the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap_prog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
