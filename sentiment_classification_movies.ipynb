{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Sentiment classification for a movie data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "[\"The undoubted highlight of this movie is Peter O'Toole's performance. In turn wildly comical and terribly terribly tragic. Does anybody do it better than O'Toole? I don't think so. What a great face that man has!<br /><br />The story is an odd one and quite disturbing and emotionally intense in parts (especially toward the end) but it is also oddly touching and does succeed on many levels. However, I felt the film basically revolved around Peter O'Toole's luminous performance and I'm sure I wouldn't have enjoyed it even half as much if he hadn't been in it.\", 1]\n",
      "\n",
      "Number of test reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "['Although credit should have been given to Dr. Seuess for stealing the story-line of \"Horton Hatches The Egg\", this was a fine film. It touched both the emotions and the intellect. Due especially to the incredible performance of seven year old Justin Henry and a script that was sympathetic to each character (and each one\\'s predicament), the thought provoking elements linger long after the tear jerking ones are over. Overall, superior acting from a solid cast, excellent directing, and a very powerful script. The right touches of humor throughout help keep a \"heavy\" subject from becoming tedious or difficult to sit through. Lastly, this film stands the test of time and seems in no way dated, decades after it was released.', 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Loading json\n",
    "with open(\"ressources/json_pol\",encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "    json_data = json.loads(data[0])\n",
    "    train = json_data[\"train\"]\n",
    "    test = json_data[\"test\"]\n",
    "\n",
    "# Quick Check\n",
    "counter_train = Counter((x[1] for x in train))\n",
    "counter_test = Counter((x[1] for x in test))\n",
    "print(\"Number of train reviews : \", len(train))\n",
    "print(\"----> # of positive : \", counter_train[1])\n",
    "print(\"----> # of negative : \", counter_train[0])\n",
    "print(\"\")\n",
    "print(train[0])\n",
    "print(\"\")\n",
    "print(\"Number of test reviews : \",len(test))\n",
    "print(\"----> # of positive : \", counter_test[1])\n",
    "print(\"----> # of negative : \", counter_test[0])\n",
    "\n",
    "print(\"\")\n",
    "print(test[0])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From TRAIN data set\n",
    "classes = [pol for text,pol in train] # y_train\n",
    "corpus = [text for text,pol in train] # X_train\n",
    "\n",
    "# From TEST data set\n",
    "true = [pol for text,pol in test] #y_test\n",
    "test_corpus = [text for text,pol in test] #X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "dic_bagOfWords = {\n",
    "    \"default\": [CountVectorizer()],\n",
    "    \"stopwords\": [CountVectorizer(stop_words='english')],\n",
    "    \"rm frequent\": [CountVectorizer(max_df=0.9)],\n",
    "    \"rm rare\": [CountVectorizer(min_df=0.1)], \n",
    "    \"bigram\": [CountVectorizer(ngram_range=(2,2))],\n",
    "    \"uni and bigram\": [CountVectorizer(ngram_range=(1,2))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def eval_preprocessing(train_corpus=corpus, test_corpus=test_corpus, train_classes=classes, test_classes=true, dic_levels=dic_bagOfWords):\n",
    "    for title, vecto in list(dic_levels.items()):\n",
    "        vectorizer = vecto[0]\n",
    "        X = vectorizer.fit_transform(train_corpus)\n",
    "        \n",
    "        #Naïve Bayes\n",
    "        nb_clf = MultinomialNB()\n",
    "        nb_clf.fit(X, train_classes)\n",
    "\n",
    "        #Logistic Regression\n",
    "        lr_clf = LogisticRegression(random_state=0, solver='lbfgs',n_jobs=-1)\n",
    "        lr_clf.fit(X, train_classes)\n",
    "\n",
    "        #Linear SVM\n",
    "        svm_clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "        svm_clf.fit(X, train_classes)\n",
    "\n",
    "        X_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "        pred_nb = nb_clf.predict(X_test)\n",
    "        pred_lr = lr_clf.predict(X_test)\n",
    "        pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "        acc_nb = accuracy_score(test_classes, pred_nb)\n",
    "        acc_lr = accuracy_score(test_classes, pred_lr)\n",
    "        acc_svm = accuracy_score(test_classes, pred_svm)\n",
    "\n",
    "        print(f\"Naïve Bayes accuracy for {title}: {acc_nb}\")\n",
    "        print(f\"Logistic Regression accuracy for {title}: {acc_lr}\")\n",
    "        print(f\"SVM accuracy for {title}: {acc_svm}\")\n",
    "\n",
    "        dic_levels[title].extend([acc_nb, acc_lr, acc_svm])\n",
    "\n",
    "    return dic_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for default: 0.81356\n",
      "Logistic Regression accuracy for default: 0.86392\n",
      "SVM accuracy for default: 0.84576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for stopwords: 0.81968\n",
      "Logistic Regression accuracy for stopwords: 0.85776\n",
      "SVM accuracy for stopwords: 0.83468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for rm frequent: 0.81484\n",
      "Logistic Regression accuracy for rm frequent: 0.86264\n",
      "SVM accuracy for rm frequent: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for rm rare: 0.71804\n",
      "Logistic Regression accuracy for rm rare: 0.77152\n",
      "SVM accuracy for rm rare: 0.76488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for bigram: 0.87016\n",
      "Logistic Regression accuracy for bigram: 0.88028\n",
      "SVM accuracy for bigram: 0.87576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for uni and bigram: 0.85692\n",
      "Logistic Regression accuracy for uni and bigram: 0.89644\n",
      "SVM accuracy for uni and bigram: 0.8912\n"
     ]
    }
   ],
   "source": [
    "eval_bagOfWords = eval_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>rm frequent</th>\n",
       "      <th>rm rare</th>\n",
       "      <th>bigram</th>\n",
       "      <th>uni and bigram</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>CountVectorizer(stop_words='english')</td>\n",
       "      <td>CountVectorizer(max_df=0.9)</td>\n",
       "      <td>CountVectorizer(min_df=0.1)</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2))</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naiveBayes</th>\n",
       "      <td>0.81356</td>\n",
       "      <td>0.81968</td>\n",
       "      <td>0.81484</td>\n",
       "      <td>0.71804</td>\n",
       "      <td>0.87016</td>\n",
       "      <td>0.85692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticRegression</th>\n",
       "      <td>0.86392</td>\n",
       "      <td>0.85776</td>\n",
       "      <td>0.86264</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>0.88028</td>\n",
       "      <td>0.89644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.84576</td>\n",
       "      <td>0.83468</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.76488</td>\n",
       "      <td>0.87576</td>\n",
       "      <td>0.8912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              default                              stopwords  \\\n",
       "index                                                                          \n",
       "model               CountVectorizer()  CountVectorizer(stop_words='english')   \n",
       "naiveBayes                    0.81356                                0.81968   \n",
       "logisticRegression            0.86392                                0.85776   \n",
       "SVM                           0.84576                                0.83468   \n",
       "\n",
       "                                    rm frequent                      rm rare  \\\n",
       "index                                                                          \n",
       "model               CountVectorizer(max_df=0.9)  CountVectorizer(min_df=0.1)   \n",
       "naiveBayes                              0.81484                      0.71804   \n",
       "logisticRegression                      0.86264                      0.77152   \n",
       "SVM                                      0.8448                      0.76488   \n",
       "\n",
       "                                                 bigram  \\\n",
       "index                                                     \n",
       "model               CountVectorizer(ngram_range=(2, 2))   \n",
       "naiveBayes                                      0.87016   \n",
       "logisticRegression                              0.88028   \n",
       "SVM                                             0.87576   \n",
       "\n",
       "                                         uni and bigram  \n",
       "index                                                    \n",
       "model               CountVectorizer(ngram_range=(1, 2))  \n",
       "naiveBayes                                      0.85692  \n",
       "logisticRegression                              0.89644  \n",
       "SVM                                              0.8912  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bow = pd.DataFrame(eval_bagOfWords)\n",
    "eval_bow.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_bow = eval_bow.set_index('index')\n",
    "eval_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_bagOfWords_v2 = {\n",
    "    \"default\": [CountVectorizer()],\n",
    "    \"rm frequent\": [CountVectorizer(max_df=0.9)],\n",
    "    \"bigram\": [CountVectorizer(ngram_range=(2,2))],\n",
    "    \"uni and bigram\": [CountVectorizer(ngram_range=(1,2))],\n",
    "    'trigram': [CountVectorizer(ngram_range=(3,3))],\n",
    "    'uni to trigram': [CountVectorizer(ngram_range=(1,3))],\n",
    "    'bi to trigram': [CountVectorizer(ngram_range=(2,3))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for default: 0.81356\n",
      "Logistic Regression accuracy for default: 0.86392\n",
      "SVM accuracy for default: 0.84576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for rm frequent: 0.81484\n",
      "Logistic Regression accuracy for rm frequent: 0.86264\n",
      "SVM accuracy for rm frequent: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for bigram: 0.87016\n",
      "Logistic Regression accuracy for bigram: 0.88028\n",
      "SVM accuracy for bigram: 0.87576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for uni and bigram: 0.85692\n",
      "Logistic Regression accuracy for uni and bigram: 0.89644\n",
      "SVM accuracy for uni and bigram: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for trigram: 0.87284\n",
      "Logistic Regression accuracy for trigram: 0.84256\n",
      "SVM accuracy for trigram: 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for uni to trigram: 0.87296\n",
      "Logistic Regression accuracy for uni to trigram: 0.89828\n",
      "SVM accuracy for uni to trigram: 0.89624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/afonso/miniconda3/envs/ap_prog/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes accuracy for bi to trigram: 0.88032\n",
      "Logistic Regression accuracy for bi to trigram: 0.87948\n",
      "SVM accuracy for bi to trigram: 0.88128\n"
     ]
    }
   ],
   "source": [
    "eval_bagOfWords_v2 = eval_preprocessing(dic_levels=dic_bagOfWords_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>rm frequent</th>\n",
       "      <th>bigram</th>\n",
       "      <th>uni and bigram</th>\n",
       "      <th>trigram</th>\n",
       "      <th>uni to trigram</th>\n",
       "      <th>bi to trigram</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>CountVectorizer()</td>\n",
       "      <td>CountVectorizer(max_df=0.9)</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 2))</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>CountVectorizer(ngram_range=(3, 3))</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>CountVectorizer(ngram_range=(2, 3))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naiveBayes</th>\n",
       "      <td>0.81356</td>\n",
       "      <td>0.81484</td>\n",
       "      <td>0.87016</td>\n",
       "      <td>0.85692</td>\n",
       "      <td>0.87284</td>\n",
       "      <td>0.87296</td>\n",
       "      <td>0.88032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticRegression</th>\n",
       "      <td>0.86392</td>\n",
       "      <td>0.86264</td>\n",
       "      <td>0.88028</td>\n",
       "      <td>0.89644</td>\n",
       "      <td>0.84256</td>\n",
       "      <td>0.89828</td>\n",
       "      <td>0.87948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.84576</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.87576</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>0.89624</td>\n",
       "      <td>0.88128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              default                  rm frequent  \\\n",
       "index                                                                \n",
       "model               CountVectorizer()  CountVectorizer(max_df=0.9)   \n",
       "naiveBayes                    0.81356                      0.81484   \n",
       "logisticRegression            0.86392                      0.86264   \n",
       "SVM                           0.84576                       0.8448   \n",
       "\n",
       "                                                 bigram  \\\n",
       "index                                                     \n",
       "model               CountVectorizer(ngram_range=(2, 2))   \n",
       "naiveBayes                                      0.87016   \n",
       "logisticRegression                              0.88028   \n",
       "SVM                                             0.87576   \n",
       "\n",
       "                                         uni and bigram  \\\n",
       "index                                                     \n",
       "model               CountVectorizer(ngram_range=(1, 2))   \n",
       "naiveBayes                                      0.85692   \n",
       "logisticRegression                              0.89644   \n",
       "SVM                                              0.8912   \n",
       "\n",
       "                                                trigram  \\\n",
       "index                                                     \n",
       "model               CountVectorizer(ngram_range=(3, 3))   \n",
       "naiveBayes                                      0.87284   \n",
       "logisticRegression                              0.84256   \n",
       "SVM                                              0.8434   \n",
       "\n",
       "                                         uni to trigram  \\\n",
       "index                                                     \n",
       "model               CountVectorizer(ngram_range=(1, 3))   \n",
       "naiveBayes                                      0.87296   \n",
       "logisticRegression                              0.89828   \n",
       "SVM                                             0.89624   \n",
       "\n",
       "                                          bi to trigram  \n",
       "index                                                    \n",
       "model               CountVectorizer(ngram_range=(2, 3))  \n",
       "naiveBayes                                      0.88032  \n",
       "logisticRegression                              0.87948  \n",
       "SVM                                             0.88128  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bow_v2 = pd.DataFrame(eval_bagOfWords_v2)\n",
    "eval_bow_v2.loc[:, 'index'] = [\"model\", 'naiveBayes', 'logisticRegression', 'SVM']\n",
    "eval_bow_v2 = eval_bow_v2.set_index('index')\n",
    "eval_bow_v2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ap_prog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
